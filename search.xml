<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JVM 参数设置]]></title>
    <url>%2Fjvm-parameters%2F</url>
    <content type="text"><![CDATA[JDK8-废弃永久代（PermGen）迎来元空间（Metaspace）移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代。JVM内存为两块：PermanentSapce和HeapSpacePermanentSapce：存放代码的(字节码)HeapSpace：堆其中HeapSpace= {Old + NEW {= Eden , from, to } }一般设置一下内存大小和回收策略就行了参数-server：一定要作为第一个参数，在多个 CPU 时性能佳，还有一种叫-client:的模式，特点是启动速度比较快，但运行时性能和内存管理效率不高，通常用于客户端应用程序或开发调试，在 32 位环境下直接运行 Java 程序默认启用该模式。Server 模式的特点是启动速度比较慢，但运行时性能和内存管理效率很高，适用于生产环境，在具有 64 位能力的 JDK 环境下默认启用该模式，可以不配置该参数。-Xms：表示 Java 初始化堆的大小，-Xms 与-Xmx 设成一样的值，避免 JVM 反复重新申请内存，导致性能大起大落，默认值为物理内存的 1/64，默认（MinHeapFreeRatio参数可以调整）空余堆内存小于 40% 时，JVM 就会增大堆直到 -Xmx 的最大限制。-Xmx：表示最大 Java 堆大小，当应用程序需要的内存超出堆的最大值时虚拟机就会提示内存溢出，并且导致应用服务崩溃，因此一般建议堆的最大值设置为可用内存的最大值的80%。如何知道我的 JVM 能够使用最大值，使用 java -Xmx512M -version 命令来进行测试，然后逐渐的增大 512 的值,如果执行正常就表示指定的内存大小可用，否则会打印错误信息，默认值为物理内存的 1/4，默认（MinHeapFreeRatio参数可以调整）空余堆内存大于 70% 时，JVM 会减少堆直到-Xms 的最小限制。-Xss：表示每个 Java 线程堆栈大小，JDK 5.0 以后每个线程堆栈大小为 1M，以前每个线程堆栈大小为 256K。根据应用的线程所需内存大小进行调整，在相同物理内存下，减小这个值能生成更多的线程，但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在 3000~5000 左右。一般小的应用， 如果栈不是很深， 应该是128k 够用的，大的应用建议使用 256k 或 512K，一般不易设置超过 1M，要不然容易出现out ofmemory。这个选项对性能影响比较大，需要严格的测试。-XX:NewSize：设置新生代内存大小。-XX:MaxNewSize：设置最大新生代新生代内存大小-XX:PermSize：设置持久代内存大小JDK8 后被抛弃，使用-XX:MetaspaceSize替代，一般不需要调整-XX:MaxPermSize：设置最大值持久代内存大小，永久代不属于堆内存，堆内存只包含新生代和老年代。JDK8 后被抛弃，使用-XX:MaxMetaspaceSize替代,一般不需要调整-XX:MaxPermSize=sizeSets the maximum permanent generation space size (in bytes). This option was deprecated in JDK 8, and superseded by the -XX:MaxMetaspaceSize option.-XX:PermSize=sizeSets the space (in bytes) allocated to the permanent generation that triggers a garbage collection if it is exceeded. This option was deprecated un JDK 8, and superseded by the -XX:MetaspaceSize option.-XX:MaxMetaspaceSize=sizeSets the maximum amount of native memory that can be allocated for class metadata. By default, the size is not limited. The amount of metadata for an application depends on the application itself, other running applications, and the amount of memory available on the system.The following example shows how to set the maximum class metadata size to 256 MB:-XX:MaxMetaspaceSize=256m-XX:MetaspaceSize=sizeSets the size of the allocated class metadata space that will trigger a garbage collection the first time it is exceeded. This threshold for a garbage collection is increased or decreased depending on the amount of metadata used. The default size depends on the platform.因为默认的类的元数据分配只受本地内存大小的限制，也就是说本地内存剩余多少，理论上Metaspace就可以有多大-XX:+AggressiveOpts：作用如其名（aggressive），启用这个参数，则每当 JDK 版本升级时，你的 JVM 都会使用最新加入的优化技术（如果有的话）。-XX:+DisableExplicitGC：禁用System.gc() ,在 程序代码中不允许有显示的调用“System.gc()”。每次在到操作结束时手动调用 System.gc() 一下，付出的代价就是系统响应时间严重降低，就和关于 Xms，Xmx 里的解释的原理一样，这样去调用 GC 导致系统的 JVM 大起大落。-Xmn：新生代的内存空间大小，可以替代-XX:NewSize,-XX:MaxNewSize对-XX:newSize、-XX:MaxnewSize两个参数同时进行配置（注意：JDK1.4之后才有该参数）。-Duser.timezone=Asia/Shanghai：设置用户所在时区。-XX:NewRatio：年轻代（包括 Eden 和两个 Survivor 区）与年老代的比值（除去持久代），-XX:NewRatio=4 表示年轻代与年老代所占比值为 1:4，年轻代占整个堆栈的 1/5，Xms=Xmx 并且设置了 Xmn 的情况下，该参数不需要进行设置。-XX:SurvivorRatio：Eden 区与 Survivor 区的大小比值，设置为 8，表示 2 个 Survivor 区（JVM 堆内存年轻代中默认有 2 个大小相等的 Survivor 区）与 1 个 Eden 区的比值为 2:8，即 1 个 Survivor 区占整个年轻代大小的 1/10。-XX:+UseConcMarkSweepGC：设置年老代为并发收集，即 CMS gc，这一特性只有 jdk1.5后续版本才具有的功能，它使用的是 gc 估算触发和 heap 占用触发。我们知道频频繁的 GC 会造面 JVM的大起大落从而影响到系统的效率，因此使用了 CMS GC 后可以在 GC 次数增多的情况下，每次 GC 的响应时间却很短，比如说使用了 CMSGC 后经过 jprofiler 的观察，GC 被触发次数非常多，而每次 GC 耗时仅为几毫秒。-XX:+UseParNewGC：对新生代采用多线程并行回收，这样收得快，注意最新的 JVM 版本，当使用 -XX:+UseConcMarkSweepGC 时，-XX:UseParNewGC 会自动开启。因此，如果年轻代的并行 GC 不想开启，可以通过设置 -XX：-UseParNewGC 来关掉。资料Configuring the Default JVM and Java Arguments官方文档JVM 参数介绍官方文档JVM中的-Xms -Xmx -XX:newSize -XX:MaxnewSize -Xmn -XX:PermSize -XX:MaxPermSize区别介绍生产环境的tomcat调优和jvm调化JVM调优总结，比较详细java–jvm启动的参数JVM垃圾回收机制与内存回收]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Failed to start LSB]]></title>
    <url>%2FFailed-to-start-LSB%2F</url>
    <content type="text"><![CDATA[不知道怎么了，网络突然不行了查了一下说是网卡的mac地址和配置文件的不一致看了下我的网卡配置 /etc/sysconfig/network-scripts/ifcfg-ens11我根本没有配置HWADDR 属性看到其他地方说是NetworkManager 服务导致的我先把他停止，然后启动网络服务，在重新启动网络管理服务，解决了123systemctl stop NetworkManagersystemctl start networksystemctl start NetworkManager]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gradle 打包jar的几种方式]]></title>
    <url>%2FGradle-Generate-Jar%2F</url>
    <content type="text"><![CDATA[jar任务打包成一个Jar12345678910jar &#123; from &#123; //添加依懒到打包文件 //configurations.compile.collect &#123; it.isDirectory() ? it : zipTree(it) &#125; configurations.runtime.collect&#123;zipTree(it)&#125; &#125; manifest &#123; attributes &apos;Main-Class&apos;: appMainClass &#125;&#125;打包成多个Jar12345678910111213141516jar &#123; manifest &#123; attributes &apos;Main-Class&apos;: appMainClass &#125;&#125;task clearJar(type: Delete) &#123; delete &apos;build/libs/lib&apos;&#125;task copyJar(type: Copy) &#123; from configurations.runtime into(&apos;build/libs/lib&apos;)&#125;task release(type: Copy, dependsOn: [build, clearJar, copyJar])执行命令gradle release或者./gradlew relesse，可在build/libs查看生成的jar包两种方式都各有缺陷，打包成一个Jar当依懒比较多情况下Jar包会很大，其它工程要要单独引用某个Jar不方便；打包成多个Jar没有启动脚本，不熟悉Java的新手不懂得运行。application插件12apply plugin: &apos;application&apos;mainClassName = appMainClass执行命令gradle build或者./gradlew build，查看build/distributions会有两个压缩文件，压缩文件包含了两个文件夹，bin为启动脚本，lib则是软件jar包和依赖。还可以执行./gradlew installDist生成未压缩文件目录build/install。这种方式最为简单，不需要添加复杂的脚本，打包成多个jar并生成启动脚本可一键运行全部脚本参考1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556def appMainClass = &apos;HelloWorldKt&apos;apply plugin: &apos;java&apos;apply plugin: &apos;kotlin&apos;apply plugin: &apos;maven&apos;archivesBaseName = &apos;app&apos;// 生成启动脚本打包//apply plugin: &apos;application&apos;//mainClassName = appMainClasssourceCompatibility = 1.8repositories &#123; mavenCentral()&#125;dependencies &#123; compile &quot;org.jetbrains.kotlin:kotlin-stdlib-jre8:$kotlin_version&quot; testCompile group: &apos;junit&apos;, name: &apos;junit&apos;, version: &apos;4.12&apos;&#125;compileKotlin &#123; kotlinOptions.jvmTarget = &quot;1.8&quot;&#125;compileTestKotlin &#123; kotlinOptions.jvmTarget = &quot;1.8&quot;&#125;jar &#123; configurations.runtime.each &#123; println it.path &#125; println &quot;=========&quot; configurations.compile.each &#123; println it.path &#125; println &quot;=========&quot; from &#123; //添加依懒到打包文件 //configurations.compile.collect &#123; it.isDirectory() ? it : zipTree(it) &#125; configurations.runtime.collect &#123; zipTree(it) &#125; &#125; manifest &#123; attributes &apos;Main-Class&apos;: appMainClass &#125;&#125;task clearJar(type: Delete) &#123; delete &apos;build/libs/lib&apos;&#125;task copyJar(type: Copy) &#123; from configurations.runtime into(&apos;build/libs/lib&apos;)&#125;task release(type: Copy, dependsOn: [build, clearJar, copyJar])Gradle - 将依赖和资源文件打入jar包用以下build.gradle打包出来的jar包，依赖是分离的：123456789101112131415161718192021222324252627282930313233apply plugin: &apos;java&apos;dependencies &#123; compile &apos;commons-codec:commons-codec:1.4&apos; compile &apos;commons-logging:commons-logging:1.1.1&apos; compile &apos;com.google.code.gson:gson:2.4&apos; compile &apos;org.apache.httpcomponents:httpclient:4.3.6&apos; compile &apos;com.strategicgains:RestExpress:0.11.2&apos; compile &apos;com.fasterxml.jackson.core:jackson-databind:2.6.4&apos; compile &apos;com.fasterxml.jackson.core:jackson-core:2.6.4&apos; compile &apos;com.fasterxml.jackson.core:jackson-annotations:2.6.4&apos; compile &quot;ch.qos.logback:logback-core:1.1.3&quot; compile &quot;ch.qos.logback:logback-classic:1.1.3&quot; compile &apos;net.kencochrane.raven:raven-logback:6.0.0&apos; compile &apos;net.kencochrane.raven:raven:6.0.0&apos; compile &quot;org.slf4j:slf4j-api:1.7.13&quot; compile &apos;com.rabbitmq:amqp-client:4.1.0&apos; compile &apos;org.apache.commons:commons-lang3:3.4&apos; compile &apos;commons-net:commons-net:3.4&apos; compile &apos;org.zeromq:jeromq:0.3.5&apos; compile fileTree(dir: &apos;libs&apos;, include: [&apos;*.jar&apos;]) compile project(&apos;:tc-das&apos;) compile project(&apos;:result-compare&apos;)&#125;jar &#123; manifest &#123; attributes( &quot;Manifest-Version&quot;: 1.0, &quot;Main-Class&quot;: &quot;com.testbird.rio.Main&quot;, &quot;Class-Path&quot;: configurations.compile.collect &#123; &quot;lib/$&#123;it.name&#125;&quot; &#125;.join(&apos; &apos;)) &#125;&#125;将build.gradle修改一下，就能将依赖和资源文件打入jar包了：123456789101112131415161718192021222324252627282930313233343536apply plugin: &apos;java&apos;dependencies &#123; compile &apos;commons-codec:commons-codec:1.4&apos; compile &apos;commons-logging:commons-logging:1.1.1&apos; compile &apos;com.google.code.gson:gson:2.4&apos; compile &apos;org.apache.httpcomponents:httpclient:4.3.6&apos; compile &apos;com.strategicgains:RestExpress:0.11.2&apos; compile &apos;com.fasterxml.jackson.core:jackson-databind:2.6.4&apos; compile &apos;com.fasterxml.jackson.core:jackson-core:2.6.4&apos; compile &apos;com.fasterxml.jackson.core:jackson-annotations:2.6.4&apos; compile &quot;ch.qos.logback:logback-core:1.1.3&quot; compile &quot;ch.qos.logback:logback-classic:1.1.3&quot; compile &apos;net.kencochrane.raven:raven-logback:6.0.0&apos; compile &apos;net.kencochrane.raven:raven:6.0.0&apos; compile &quot;org.slf4j:slf4j-api:1.7.13&quot; compile &apos;com.rabbitmq:amqp-client:4.1.0&apos; compile &apos;org.apache.commons:commons-lang3:3.4&apos; compile &apos;commons-net:commons-net:3.4&apos; compile &apos;org.zeromq:jeromq:0.3.5&apos; compile fileTree(dir: &apos;libs&apos;, include: [&apos;*.jar&apos;]) compile project(&apos;:tc-das&apos;) compile project(&apos;:result-compare&apos;)&#125;jar &#123; manifest &#123; attributes( &quot;Manifest-Version&quot;: 1.0, &quot;Main-Class&quot;: &quot;com.testbird.rio.Main&quot;) &#125; from &#123; configurations.compile.collect &#123; it.isDirectory() ? it : zipTree(it) &#125; &#125; into(&apos;assets&apos;) &#123; from &apos;assets&apos; &#125;&#125;Gradle 打包jar的几种方式Gradle - 将依赖和资源文件打入jar包]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 修改最大打开文件数量]]></title>
    <url>%2Fchange-linux-max-open-file%2F</url>
    <content type="text"><![CDATA[查看1ulimit -n临时修改1ulimit -n 65535永久修改在/etc/security/limits.conf加入12* soft nofile 65535* hard nofile 65535* 表示所有用户注意用户最大打开文件数量不能大于系统规定的打开数量查看系统最大打开文件数量1cat /proc/sys/fs/file-max临时修改系统最大打开文件数量直接修改上面的文件中的数字即可永久修改在/etc/sysctl.conf加入1fs.file-max = 6553560如果要通过安全shell（SSH）访问还应编辑/etc/ssh/sshd_config并取消注释以下行：1#UseLogin no并将其值设置yes为如下所示：1UseLogin yes1ssh restart重新启动计算机以使限制生效并使用以下命令验证是否已设置新限制：1ulimit -aWith systemd (Recent Linux Distributions)比如Centos 7可以修改/etc/systemd/system.conf中的1DefaultLimitNOFILE重启后生效针对单独的进程可以设置/etc/systemd/system/xxx.service.d/limits.confxxx是进程12[Service]LimitNOFILE=64000]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 入门教程]]></title>
    <url>%2Frabbitmq%2F</url>
    <content type="text"><![CDATA[什么是MQ为什么使用MQ为什么选择RabbitMQ怎么安装RabbitMQRabbitMQ怎么使用RabbitMQ概念RabbitMQ消息事物RabbitMQ消息确认RabbitMQ配置RabbitMQ集群帮助当前版本CentOS 7Erlang 21.xRabbitMQ 3.7.14什么是MQ,为什么要使用MQ哈，MQ你都不知道，你还来这里，茨~ 快去百度啦为什么使用MQ话说，你都不知道为什么使用MQ，那你还来这里干嘛？为什么选择RabbitMQ现在的市面上有很多MQ可以选择，比如ActiveMQ、ZeroMQ、Appche Qpid，那问题来了为什么要选择RabbitMQ？除了Qpid，RabbitMQ是唯一一个实现了AMQP标准的消息服务器；可靠性，RabbitMQ的持久化支持，保证了消息的稳定性；高并发，RabbitMQ使用了Erlang开发语言，Erlang是为电话交换机开&gt; 发4. 的语言，天生自带高并发光环，和高可用特性；集群部署简单，正是应为Erlang使得RabbitMQ集群部署变的超级简单；社区活跃度高，根据网上资料来看，RabbitMQ也是首选；MQ 对比我们先来看一些数据阿里官网对比功能消息队列 RocketMQApache RocketMQ（开源）消息队列 KafkaApache Kafka（开源）RabbitMQ（开源）安全防护支持不支持支持不支持支持主子账号支持支持不支持支持不支持不支持可靠性同步刷盘 - 同步双写 - 超3份数据副本 - 99.99999999%- 同步刷盘 - 异步刷盘 -同步刷盘 - 同步双写 - 超3份数据副本 - 99.99999999%异步刷盘，丢数据概率高同步刷盘可用性- 非常好，99.95% - Always Writable好- 非常好，99.95% - Always Writable好好横向扩展能力- 支持平滑扩展 - 支持百万级 QPS支持- 支持平滑扩展 - 支持百万级 QPS支持- 集群扩容依赖前端 - LVS 负载均衡调度Low Latency支持不支持支持不支持不支持消费模型Push / PullPush / PullPush / PullPullPush / Pull定时消息支持（可精确到秒级）支持（只支持18个固定 Level）暂不支持不支持支持事务消息支持不支持不支持不支持不支持顺序消息支持支持暂不支持支持不支持全链路消息轨迹支持不支持暂不支持不支持不支持消息堆积能力百亿级别 不影响性能百亿级别 影响性能百亿级别 不影响性能影响性能影响性能消息堆积查询支持支持支持不支持不支持消息回溯支持支持支持不支持不支持消息重试支持支持暂不支持不支持支持死信队列支持支持不支持不支持支持性能（常规）非常好 百万级 QPS非常好 十万级 QPS非常好 百万级 QPS非常好 百万级 QPS一般 万级 QPS性能（万级 Topic 场景）非常好 百万级 QPS非常好 十万级 QPS非常好 百万级 QPS低低性能（海量消息堆积场景）非常好 百万级 QPS非常好 十万级 QPS非常好 百万级 QPS低低xxxxxxxxxxxxxxxxxxActiveMQRabbitMQRocketMqZeroMQKafka关注度高高中中高成熟度成熟成熟比较成熟不成熟成熟所属社区/公司ApacheMozilla Public LicenseAlibaba Apache社区活跃度高高中低高文档多多中中多特点功能齐全，被大量开源项目使用由于Erlang 语言的并发能力，性能很好各个环节分布式扩展设计，主从 HA；支持上万个队列；多种消费模式；性能很好低延时，高性能，最高 43万条消息每秒授权方式开源开源开源开源开源开发语言JavaErlangJavaC支持的协议OpenWire、STOMP、REST、XMPP、AMQPAMQP 自己定义的一套(社区提供JMS–不成熟)TCP、UDP客户端支持语言Java、C、C++、Python、PHP、Perl、.net 等Java、C、C++、Python、PHP、Perl、.net 等Java C++（不成熟）python java、 php、.net 等持久化内存、文件、数据库内存、文件磁盘文件在消息发送端保存事务支持不支持支持不支持集群支持支持支持不支持负载均衡支持支持支持不支持管理界面一般好无社区有 web console 实现无部署方式独立、嵌入独立独立独立顺序无法保证严格的顺序保证严格的消费顺序优点成熟的产品，已经在很多公司得到应用（非大规模场景）。有较多的文档。各种协议支持较好，有多重语言的成熟的客户端；由于erlang语言的特性，mq 性能较好；管理界面较丰富，在互联网公司也有较大规模的应用；支持amqp系诶，有多中语言且支持 amqp 的客户端可用模型简单，接口易用（JMS 的接口很多场合并不太实用）。在阿里大规模应用。目前支付宝中的余额宝等新兴产品均使用rocketmq。集群规模大概在50 台左右，单日处理消息上百亿；性能非常好，可以大量堆积消息在broker 中；支持多种消费，包括集群消费、广播消费等。开发度较活跃，版本更新很快。缺点根据其他用户反馈，会出莫名其妙的问题，切会丢失消息。 其重心放到activemq6.0 产品—apollo 上去了，目前社区不活跃，且对 5.x 维护较少;Activemq 不适合用于上千个队列的应用场景erlang语言难度较大。集群不支持动态扩展。没有在 mq 核心中去实现JMS 等接口知道了吗？为什么选择RabbitMQ！！！！！！(小声的说：其实！！！我也没用过MQ，各大厂商都实现了一套，所以我准备选择一个先了解一下)为什么选择RabbitMQ呢？因为我也是第一次接触MQ，选择的原因嘛，是RabbitMQ时间比较久了，资料比较多，刚入手肯定选择资料比较多的最好还有Rabbit是兔子的意思嘛，一想到兔子，很可爱啊！！！怎么安装RabbitMQ打开官网看了吗？Download + Installation哈！！！没看到，你网速太差了吧，那你等一下吧！还是没看到！哦，那你点击一下我吧！啊~~ ~别点了~啊~~~～(￣▽￣～)我怀疑你在开车，但是我没有证据OK，现在到这里了我的是CentOS7 所以我点击这个其他的系统自己研究了~ RabbitMQ 是Erlange开发了，所以要先安装Erlang，版本有要求哦进来后看到Install Erlang下面有一个a package 的一个链接，点击跳转到了Github往下面拉，这里我选择最新版本的Erlang 源，Erlang 21.x，当前版本的RabbitMQ3.7.14 也要求Erlang &gt;= 19.3在往下拉，可以看到指定版本的Erlang 安装源源安装好像有两种 Package Cloud、Bintray Yum Repositories我选择第一种的，但是我没有操作这个Package Cloud supports a variety of options for RPM package installation: from Yum configuration to shell scripts to Chef and Puppet.See Package Cloud repository installation page for details.也安装好了~嘛 再往下拉就能看到Bintray Yum Repositories，也可以用这个源安装12345678910111213141516171819202122# In /etc/yum.repos.d/rabbitmq_erlang.repo[rabbitmq_erlang]name=rabbitmq_erlangbaseurl=https://packagecloud.io/rabbitmq/erlang/el/7/$basearchrepo_gpgcheck=1gpgcheck=0enabled=1gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkeysslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtmetadata_expire=300 [rabbitmq_erlang-source]name=rabbitmq_erlang-sourcebaseurl=https://packagecloud.io/rabbitmq/erlang/el/7/SRPMSrepo_gpgcheck=1gpgcheck=0enabled=1gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkeysslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtmetadata_expire=300配置好后就安装了~1yum install -y erlang安装好Erlang后开始安装RabbitMQ了我们回到这里，快点击我啊~这里使用Bintray 安装1rpm --import https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc1234567# In /etc/yum.repos.d/rabbitmq.repo[bintray-rabbitmq-server]name=bintray-rabbitmq-rpmbaseurl=https://dl.bintray.com/rabbitmq/rpm/rabbitmq-server/v3.7.x/el/7/gpgcheck=0repo_gpgcheck=0enabled=1写完配置后，安装，没有指定版本号默认安装最新版,我这里的是 3.7.141yum install -y rabbitmq-server.noarch启动服务RabbitMQ器设置开机启动，默认是不会开机启动，大家自己选择1chkconfig rabbitmq-server on启动RabbitMQ，Centos7 已经使用systemctl 替代 service 命令了1234567891011# 启动systemctl start rabbitmq-server # 重新启动systemctl restart rabbitmq-server # 停止systemctl stop rabbitmq-server # 状态systemctl status rabbitmq-server也可是使用RabbitMQ 提供的命令查看状态，更多关于rabbitmqctl 命令请点击这里1rabbitmqctl status我选择开启Web 管理插件12345rabbitmq-plugins enable rabbitmq_management rabbitmq-plugins disable rabbitmq_management # 注意：插件的启用和关闭都不会影响当前运行rabbitmq节点。必须重新启动之后才会影响。打开 http://localhost:15672/输入guest guest默认的用户guest只能在安装RabbitMQ的机器上登录，在其他机器登录需要新增用户！,当然利用配置文件也可以实现让guest用户在其他机器登陆！！这里我选择新建用户添加用户1rabbitmqctl add_user username password设置用户标签（administrator），用户标签的用处主要是管理插件使用的，设置administrator 是让这个用户可以访问 Web端管理程序1rabbitmqctl set_user_tags username administrator设置 虚拟主机权限，RabbitMQ 是使用虚拟主机隔离的，每一个虚拟主机都用自己的交换机和队列，每个虚拟主机互相隔离/ 是默认的虚拟主机1rabbitmqctl set_permissions username -p / ".*" ".*" ".*"设置完后就可以远程使用这个用户登录Web 管理端了常用命令User | 用户1234567891011121314151617181920# 用户列表rabbitctl list_users # 添加用户rabbitmqctl add_user username password # 删除用户rabbitmqctl delete_user username # 修改密码rabbitmqctl change_password username password # 清除密码rabbitmqcaltl clear_password username # 设置标签rabbitmqctl set_user_tags username administrator # 清空标签rabbitmqctl set_user_tags usernameAccess Control | 访问控制1234567891011121314151617181920# 虚拟主机列表rabbitmqctl list_vhosts # 添加虚拟主机rabbitmqctl add_vhost vhost # 删除虚拟主机rabbitmqctl delete_vhost vhost # 设置权限用户rabbitmqctl set_permissions -p vhost username ".*" ".*" ".*" #清空用户权限rabbitmqctl clear_permissions -p vhost username # 虚拟主机下的用户rabbitmqctl list_permissions -p vhost # 用户下的虚拟主机rabbitmqctl list_user_permissions usernameRabbitMQ怎么使用连接服务器我使用的是Java 客户端 其他语言自己查阅官方文档根据官方文档我们要引入客户端如果使用Maven12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.7.0&lt;/version&gt;&lt;/dependency&gt;如果使用Gradle123dependencies &#123; compile &apos;com.rabbitmq:amqp-client:5.7.0&apos;&#125;我们来到api文档，看看Java怎么使用RabbitMQ123456789ConnectionFactory factory = new ConnectionFactory();// "guest"/"guest" by default, limited to localhost connectionsfactory.setUsername(userName);factory.setPassword(password);factory.setVirtualHost(virtualHost);factory.setHost(hostName);factory.setPort(portNumber); Connection conn = factory.newConnection();PropertyDefault ValueUsername“guest”Password“guest”Virtual host“/“Hostname“localhost”port5672 for regular connections, 5671 for connections that use TLS还可以使用URLs方式123ConnectionFactory factory = new ConnectionFactory();factory.setUri("amqp://userName:password@hostName:portNumber/virtualHost");Connection conn = factory.newConnection();我使用URLs方式，如果你要连接到默认的虚拟主机/，需要将/转义也就是%2F，其他不用这里我直接写测试类里面了123456789101112131415161718192021222324252627282930public class Aphage &#123; private static final String uri = "amqp://%s:%s@%s:%d/%s"; private static final String HOST = "192.168.92.128"; private static final int PORT = AMQP.PROTOCOL.PORT; private static final String USERNAME= "Aqua"; private static final String PASSWORD = "Aqua"; private static final String VHOST = "%2F"; private static Connection conn = null; public Connection getConnection() throws Exception&#123; ConnectionFactory factory=new ConnectionFactory(); factory.setUri(String.format(uri,USERNAME,PASSWORD,HOST,PORT,VHOST)); return factory.newConnection(); &#125; @Before public void start() throws Exception&#123; conn = getConnection(); &#125; @After public void end() throws Exception&#123; if(null!=conn)conn.close(); &#125;&#125;声明交换机和队列并绑定声明交换机和队列的时候分为两种情况声明的交换机和队列不存在，就会创建如果存在，就不会123channel.exchangeDeclare(exchangeName, "direct", true);String queueName = channel.queueDeclare().getQueue();channel.queueBind(queueName, exchangeName, routingKey);一种持久的，非自动交换的“直接”类型具有生成名称的非持久，独占，自动删除队列123channel.exchangeDeclare(exchangeName, "direct", true);channel.queueDeclare(queueName, true, false, false, null);channel.queueBind(queueName, exchangeName, routingKey);一种持久的，非自动交换的“直接”类型具有已知名称的持久，非独占，非自动删除队列声明交换机根据上面的代码，我们先来声明一些交换机1234567891011121314151617181920212223242526272829@Testpublic void Test1() throws Exception&#123; Channel channel=conn.createChannel(); //创建交换机 /* * 1. 交换机名称 * 2. 交换机类型 * 3. 是否永久存在，false 为临时重启消失 * */ //直接类型 channel.exchangeDeclare("direct-forever", BuiltinExchangeType.DIRECT,true); channel.exchangeDeclare("direct-temporary", BuiltinExchangeType.DIRECT,false); //广播类型 routing key 忽略无效 channel.exchangeDeclare("fanout-forever", BuiltinExchangeType.FANOUT,true); channel.exchangeDeclare("fanout-temporary", BuiltinExchangeType.FANOUT,false); //广播类型 routing key 模糊匹配 channel.exchangeDeclare("topic-forever", BuiltinExchangeType.TOPIC,true); channel.exchangeDeclare("topic-temporary", BuiltinExchangeType.TOPIC,false); //使用键值对匹配 channel.exchangeDeclare("headers-forever", BuiltinExchangeType.HEADERS,true); channel.exchangeDeclare("headers-temporary", BuiltinExchangeType.HEADERS,false); channel.close();&#125;交换机类型分为四种 direct、fanout、topic、header（这个性能最差）channel 官方建议不要多线程共享，最好一个线程使用一个channel然后登陆Web 管理界面查看http://192.168.92.128:15672/#/exchanges发现已经有我们声明的交换机了其中还有一些默认的交换机我们也可以看到交换机是在虚拟主机中的、每个虚拟主机互相隔离我们也发现在Features列，永久的交换机是带有D标签的接下来我们来声明队列1234567891011121314151617181920212223242526272829303132333435@Testpublic void test2() throws Exception&#123; Channel channel=conn.createChannel(); //创建队列 /* * queue - 队列的名称 * durable - 如果我们声明一个持久队列，则为true（队列将在服务器重启后继续存在） * exclusive - 如果我们声明一个独占队列（仅限于此连接），则为true * autoDelete - 如果我们声明一个自动删除队列，则为true（服务器将在不再使用时将其删除）,消费者断开连接时是否删除队列 * arguments - 队列的其他属性（构造参数） * */ channel.queueDeclare("Aqua-forever",true,false,false,null); channel.queueDeclare("fanout1-forever",true,false,false,null); channel.queueDeclare("fanout2-forever",true,false,false,null); channel.queueDeclare("topic1-forever",true,false,false,null); channel.queueDeclare("topic2-forever",true,false,false,null); channel.queueDeclare("topic3-forever",true,false,false,null); channel.queueDeclare("headers1-forever",true,false,false,null); channel.queueDeclare("headers2-forever",true,false,false,null); //主动声明一个服务器命名的独占，自动删除，非持久队列。 String queueName = channel.queueDeclare().getQueue(); System.out.println(queueName); queueName = channel.queueDeclare().getQueue(); System.out.println(queueName); queueName = channel.queueDeclare().getQueue(); System.out.println(queueName); System.in.read(); channel.close();&#125;这里我们使用System.in.read 进行阻塞打开 http://192.168.92.128:15672/#/queues我们可以看到我们的队列已经出来了，也有一些临时队列声明队列也就两个api 函数当我们点击结束进程的时候，断开连接了，临时队列就会自动删除队列也有了，接下来就是和交换机绑定了，不然发送的数据没办法进入队列因为exchange 是负责数据转发的，而队列（queue）只是保存数据的12345678910111213141516171819202122232425262728293031323334353637@Testpublic void test3() throws Exception&#123; Channel channel=conn.createChannel(); //队列绑定交换机，一个队列可绑定多个交换机 /* * queue - 队列的名称 * exchange - 交易所的名称 * routingKey - 用于绑定的路由密钥 * */ //绑定到直接交换机 channel.queueBind("Aqua-forever","direct-forever","Aqua-1"); //绑定到广播(fanout类型，对Routing Key无效) channel.queueBind("fanout1-forever","fanout-forever","Aqua-1"); channel.queueBind("fanout2-forever","fanout-forever","Aqua-2"); //绑定到广播 routing key 模糊匹配 channel.queueBind("topic1-forever","topic-forever","Aqua.#"); channel.queueBind("topic2-forever","topic-forever","Aqua.mea.*"); channel.queueBind("topic3-forever","topic-forever","Aqua.suki.*"); //绑定到广播(fanout类型，对Routing Key无效) channel.queueBind("fanout1-forever","fanout-forever","Aqua-1"); channel.queueBind("fanout2-forever","fanout-forever","Aqua-2"); Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put("x-match", "any");//这代表消息携带的Hash是需要全部匹配键值(all)，还是仅匹配一个键值(any)就可以了 map.put("xxx","111"); map.put("aaa","bbb"); channel.queueBind("headers1-forever","headers-forever","",map); map.put("x-match", "all"); channel.queueBind("headers2-forever","headers-forever","",map); channel.close();&#125;接下来发送消息（生产消息）到服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182@Testpublic void test4() throws Exception&#123; Channel channel = conn.createChannel(); //发送消息(生产消息) channel.basicPublish("direct-forever","Aqua-1",null,getMessage().getBytes()); //routing key 直接忽略 channel.basicPublish("fanout-forever","Aqua-1",null,getMessage().getBytes()); channel.basicPublish("fanout-forever","Aqua-2",null,getMessage().getBytes()); /* topic路由器的关键在于定义路由键，定义routingKey名称不能超过255字节，使用“.”作为分隔符，例如：com.mq.rabbit.error。 消费消息的时候routingKey可以使用下面字符匹配消息： "*"匹配一个分段(用“.”分割)的内容； "#"匹配0和多个字符； 例如发布了一个“com.mq.rabbit.error”的消息： 能匹配上的路由键： cn.mq.rabbit.* cn.mq.rabbit.# #.error cn.mq.# # 不能匹配上的路由键： cn.mq.* *.error * 所以如果想要订阅所有消息，可以使用“#”匹配。 */ channel.basicPublish("topic-forever","Aqua.hello",null,getMessage().getBytes()); channel.basicPublish("topic-forever","Aqua.mea.suki",null,getMessage().getBytes()); channel.basicPublish("topic-forever","Aqua.suki.me",null,getMessage().getBytes()); Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put("xxx","111"); channel.basicPublish("headers-forever","",new AMQP.BasicProperties().builder().headers(map).build(),getMessage().getBytes()); /* void basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body) throws IOException; void basicPublish(String exchange, String routingKey, boolean mandatory, BasicProperties props, byte[] body) throws IOException; void basicPublish(String exchange, String routingKey, boolean mandatory, boolean immediate, BasicProperties props, byte[] body) throws IOException; 他们共有的参数分别是： exchange：交换机名称 routingKey：路由键 props：消息属性字段，比如消息头部信息等等 body：消息主体部分 除此之外，还有mandatory和immediate这两个参数，鉴于RabbitMQ3.0不再支持immediate标志，因此我们重点讨论mandatory标志 mandatory的作用： 当mandatory标志位设置为true时，如果exchange根据自身类型和消息routingKey无法找到一个合适的queue存储消息，那么broker会调用basic.return方法将消息返还给生产者; 当mandatory设置为false时，出现上述情况broker会直接将消息丢弃;通俗的讲，mandatory标志告诉broker代理服务器至少将消息route到一个队列中，否则就将消息return给发送者; */ //Return(int replyCode, String replyText, String exchange, String routingKey, AMQP.BasicProperties properties, byte[] body) //这里我们尝试发送无法路由的数据 channel.basicPublish("direct-forever","Aqua-tietie",true,null,getMessage().getBytes()); // channel.addReturnListener((i, s, s1, s2, basicProperties, bytes) -&gt; System.out.println(String.format("replyCode=%d replyText=%s exchange=%s routingKey=%s body=%s",i,s,s1,s2,new String(bytes,"UTF-8"))) ); System.in.read(); channel.close();&#125; public String getMessage()&#123; return (new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()) + " : Hello Aqua!!!!!!!!!!!!! prpr!!!!!!!!!!!!!");&#125;执行后可以看到控制台输出无法路由的数据1replyCode=312 replyText=NO_ROUTE exchange=direct-forever routingKey=Aqua-tietie body=2019-05-14 17:00:53 : Hello Aqua!!!!!!!!!!!!! prpr!!!!!!!!!!!!!打开 http://192.168.92.128:15672/#/queues 可以看到数据已经到达队列中了下面我们可以从消息队列中取数据了，取数据比较简单123456789101112131415161718192021222324252627282930313233343536373839404142434445 public void test5() throws Exception&#123; Channel channel = conn.createChannel(); /* * 1.队列名称 * 2. auto ack 自动确认 * 3. consumerTag 取消回调的时候用的 * 4. 接受消息回调 * 5. 回调被取消的回调 例如队列被删除，或者在集群方案中，队列所在的节点失败 * */ channel.basicConsume("Aqua-forever",false,"Aqua-listened-1",(s, delivery) -&gt; &#123; System.out.println(String.format("tag: %s exchange: %s routing key: %s",s,delivery.getEnvelope().getExchange(),delivery.getEnvelope().getRoutingKey())); System.out.println(String.format("msg: %s",new String(delivery.getBody(),"UTF-8"))); channel.basicAck(delivery.getEnvelope().getDeliveryTag(),false); &#125;,s -&gt; System.out.println("监听被取消: "+ s)); //这里我们没有进行确认，当与服务器断开连接，数据将会重新放回队列 //让其他消费者进行消费 channel.basicConsume("fanout1-forever",false,"Aqua-listened-2",(s, delivery) -&gt; &#123; System.out.println(String.format("tag: %s exchange: %s routing key: %s",s,delivery.getEnvelope().getExchange(),delivery.getEnvelope().getRoutingKey())); System.out.println(String.format("msg: %s",new String(delivery.getBody(),"UTF-8"))); //channel.basicAck(delivery.getEnvelope().getDeliveryTag(),false); &#125;,s -&gt; System.out.println("监听被取消: "+ s)); //也可是使用DefaultConsumer 官方文档用的就是这个// channel.basicConsume("Aqua-forever",false,"Aqua-listened",new DefaultConsumer(channel)&#123;// @Override// public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;////// channel.basicAck(envelope.getDeliveryTag(),false);// &#125;// &#125;); channel.addShutdownListener(e -&gt; System.out.println(String.format("连接关闭 %s %b",e.getMessage(),e.isHardError())) ); System.in.read(); channel.close(); &#125;如果autoAck设置为false，需要调用basicAck 进行确认，未确认的将放到未确认队列，如果此时客户端断开连接，将重新放回原队列如果autoAck设置为true，则服务器发送消息后，将消息从客户端移除需要查阅API 请点击RabbitMQ概念概念看图Message消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。Publisher消息的生产者，就是发送消息的，也是一个向交换器发布消息的客户端应用程序。Exchange交换器，就是转发消息的，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。Binding绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。队列绑定交换机，一个队列可以绑定多个交换机，一个交换机也可以对应多个队列，多对多关系Queue消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。Connection网络连接，比如一个TCP连接。Channel信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。其实是一个Channel对应一条TCP连接，还有官方建议不要多线程共享Channel，最好是一个线程对应一个ChannelConsumer接收消息的，消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。Virtual Host虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。Broker表示消息队列服务器实体。AMQP中的消息路由生产者发送消息到交换机，交换机根据交换机类型和参数、绑定的队列，转发到对应的队列消费者去队列取出数据Exchange 类型Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型direct消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发 routing key 标记为“dog”的消息，不会转发“dog.puppy”，也不会转发“dog.guard”等等。它是完全匹配、单播的模式。fanout每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。topictopic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号“”。#匹配0个或多个单词，匹配不多不少一个单词。basicPublish​(String exchange, String routingKey, boolean mandatory, boolean immediate, AMQP.BasicProperties props, byte[] body)basicPublish​(String exchange, String routingKey, boolean mandatory, AMQP.BasicProperties props, byte[] body)basicPublish​(String exchange, String routingKey, AMQP.BasicProperties props, byte[] body)可以根据 mandatory 进行无法路由的消息进行处理mandatory = false 无法路由的消息直接丢弃mandatory = true 无法路由的消息通过 Return 回调函数 通知immediate RabbitMQ 3.0 不再支持此标记RabbitMQ消息事务事务消息事物保证消息一定到达RabbitMQ服务器只有三个Apichannel.txSelect() 声明启动事务模式；channel.txComment() 提交事务；channel.txRollback() 回滚事务；虽然当你调用publish 发送到服务器的时候，服务器收到并不会把他立刻放到队列，只有事务提交才会进入队列事务性能很低，事务api 比较简单没有什么好描述的了扩展知识扩展知识我们知道，消费者可以使用消息自动或手动发送来确认消费消息，那如果我们在消费者模式中使用事务（当然如果使用了手动确认消息，完全用不到事务的），会发生什么呢？消费者模式使用事务假设消费者模式中使用了事务，并且在消息确认之后进行了事务回滚，那么RabbitMQ会产生什么样的变化？结果分为两种情况：autoAck=false手动应对的时候是支持事务的，也就是说即使你已经手动确认了消息已经收到了，但在确认消息会等事务的返回解决之后，在做决定是确认消息还是重新放回队列，如果你手动确认现在之后，又回滚了事务，那么已事务回滚为主，此条消息会重新放回队列；autoAck=true如果自定确认为true的情况是不支持事务的，也就是说你即使在收到消息之后在回滚事务也是于事无补的，队列已经把消息移除了；RabbitMQ消息确认Confirm发送方确认模式使用和事务类似，也是通过设置Channel进行发送方确认的。效率比事务要快Confirm的三种实现方式：channel.waitForConfirms()普通发送方确认模式；channel.waitForConfirmsOrDie()批量确认模式；channel.addConfirmListener()异步监听发送方确认模式；使用 channel.confirmSelect() 开启消息确认回调普通Confirm模式12345678910111213@Testpublic void Test77() throws Exception&#123; Channel channel = conn.createChannel(); channel.confirmSelect(); channel.basicPublish("direct-forever","Aqua-1",null,getMessage().getBytes()); if(channel.waitForConfirms()) System.out.println("发送成功"); else System.out.println("发送失败"); channel.close();&#125;批量Confirm模式123456789101112@Testpublic void Test777() throws Exception&#123; Channel channel = conn.createChannel(); channel.confirmSelect(); for (int i=0;i&lt;10;++i) channel.basicPublish("direct-forever","Aqua-1",null,getMessage().getBytes()); channel.waitForConfirmsOrDie(); System.out.println("发送成功"); channel.close();&#125;异步Confirm模式1234567891011121314151617181920212223@Testpublic void test7() throws Exception&#123; Channel channel = conn.createChannel(); channel.confirmSelect(); /* 可以看出，代码是异步执行的，消息确认有可能是批量确认的，是否批量确认在于返回的multiple的参数， 此参数为bool值，如果true表示批量执行了deliveryTag这个值以前的所有消息，如果为false的话表示单条确认。 * */ channel.addConfirmListener((l, b) -&gt; &#123; System.out.println("已经确认 "+ l + " " + b); &#125;,(l, b) -&gt; &#123; System.out.println("未确认 " + l + " " + b); &#125;); channel.basicPublish("direct-forever","Aqua-1",null,getMessage().getBytes()); channel.basicPublish("direct-forever","Aqua-1",null,getMessage().getBytes()); channel.basicPublish("direct-forever","Aqua-1",null,getMessage().getBytes()); System.in.read(); channel.close();&#125;性能比较 普通模式 &lt; 批量模式 &lt; 异步模式RabbitMQ配置文件需要自己创建rabbitmq.conf和rabbitmq-env.conf的位置这些文件的位置是特定于分发的。默认情况下，它们不是创建的，但希望位于每个平台的以下位置：通用UNIX：$RABBITMQ_HOME/etc/rabbitmq/Debian：/etc/rabbitmq/RPM：/etc/rabbitmq/Mac OS（Homebrew）：${install_prefix}/etc/rabbitmq/，Homebrew地窖前缀通常是/usr/localWindows：％APPDATA％\RabbitMQ\如果rabbitmq-env.conf不存在，则可以在由RABBITMQ_CONF_ENV_FILE变量指定的位置手动创建。在Windows系统上，它名为rabbitmq-env.bat。如果rabbitmq.conf不存在，可以手动创建。如果更改位置，请设置RABBITMQ_CONFIG_FILE环境变量。RabbitMQ自动将.conf扩展名附加到此变量的值。更改后重新启动服务器。添加或删除配置文件后，Windows服务用户需要重新安装该服务官方文档RabbitMQ集群Rabbitmq集群高可用RabbitMQ是用erlang开发的，集群非常方便，因为erlang天生就是一门分布式语言,但其本身并不支持负载均衡。Rabbit模式大概分为以下三种：单一模式、普通模式、镜像模式集群最少需要一个磁盘节点单一模式：最简单的情况，非集群模式。没什么好说的。普通模式：默认的集群模式。对于Queue来说，消息实体只存在于其中一个节点，A、B两个节点仅有相同的元数据，即队列结构。当消息进入A节点的Queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连A或B，出口总在A，会产生瓶颈。该模式存在一个问题就是当A节点故障后，B节点无法取到A节点中还未消费的消息实体。如果做了消息持久化，那么得等A节点恢复，然后才可被消费；如果没有持久化的话，然后就没有然后了……镜像模式：把需要的队列做成镜像队列，存在于多个节点，属于RabbitMQ的HA方案。该模式解决了上述问题，其实质和普通模式不同之处在于，消息实体会主动在镜像节点间同步，而不是在consumer取数据时临时拉取。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。所以在对可靠性要求较高的场合中适用(后面会详细介绍这种模式，目前我们搭建的环境属于该模式)启动磁盘节点123rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_app查看集群状态rabbit11rabbitmqctl cluster_status加入集群，只要加入其中一个节点就可以了rabbit21234rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster --ram rabbit@rabbit1rabbitmqctl start_apprabbit31234rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster --ram rabbit@rabbit1rabbitmqctl start_app退出集群12345678# on rabbit3rabbitmqctl stop_app# =&gt; Stopping node rabbit@rabbit3 ...done.rabbitmqctl reset# =&gt; Resetting node rabbit@rabbit3 ...done.rabbitmqctl start_app# =&gt; Starting node rabbit@rabbit3 ...done.使用Rabbit镜像功能，需要基于rabbitmq策略来实现，政策是用来控制和修改群集范围的某个vhost队列行为和Exchange行为在cluster中任意节点启用策略，策略会自动同步到集群节点1rabbitmqctl set_policy -p hrsystem ha-allqueue"^" '&#123;"ha-mode":"all"&#125;'这行命令在vhost名称为hrsystem创建了一个策略，策略名称为ha-allqueue,策略模式为 all 即复制到所有节点，包含新增节点，策略正则表达式为 “^” 表示所有匹配所有队列名称。例如rabbitmqctl set_policy -p hrsystem ha-allqueue “^message” ‘{“ha-mode”:”all”}’注意：”^message” 这个规则要根据自己修改，这个是指同步”message”开头的队列名称，我们配置时使用的应用于所有队列，所以表达式为”^”官方set_policy说明参见官方set_policy集群指南完结撒花帮助官网Java RabbitMQ Client Api 文档RabbitMQ Java Api官方教程生肉RabbitMQ Java Api官方教程熟肉消息队列之 RabbitMQ分布式开放消息系统(RocketMQ)的原理与实践RabbitMQ集群Rabbitmq集群高可用测试Rabbitmqctl 文档RabbitMQ系列文章]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csdn 突破正版链接直接下载]]></title>
    <url>%2Fcsdn-breakthrough-download%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233//https://download.csdn.net/download/anonymous1991/10137472//fileId=10137472//不能免积分，版权限制不能下载function csdnFileDownload(fileId)&#123; $.ajax(&#123; type: 'get', url: "/index.php/source/before_do_download/"+fileId, async: false, dataType: 'jsonp', jsonpcallback: 'jsonpcallback', success: function (resobj) &#123; var targetUrl=resobj.actionUrl+"/"+encodeURIComponent(encodeURIComponent(SMSdk.getDeviceId())); console.log(targetUrl); $.ajax(&#123; type: 'get', url: targetUrl, async: false, dataType: 'jsonp', jsonpcallback: 'jsonpcallback', success: function (resobj) &#123; console.log(resobj); location.href=resobj.msg; &#125;, error: function (err) &#123; console.log(err); &#125; &#125;); &#125;, error: function (err) &#123; console.log(err); &#125;&#125;)&#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>csdn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.Quick StartCreate a new post1$ hexo new "My New Post"More info: WritingRun server1$ hexo serverMore info: ServerGenerate static files1$ hexo generateMore info: GeneratingDeploy to remote sites1$ hexo deployMore info: Deployment]]></content>
      <categories>
        <category>事件簿</category>
      </categories>
  </entry>
</search>
